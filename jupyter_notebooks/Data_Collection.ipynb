{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Fetch and upload cherry leaves image dataset from Kaggle.\n",
    "- Prepare data for analysis and modelling.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- Kaggle authentification token [JSON file].\n",
    "- [Kaggle dataset](https://www.kaggle.com/codeinstitute/cherry-leaves).\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- Dataset split: train, validation, test sections.\n",
    "- Datasets saved to train, validation, test folders (within inputs/datasets/cherry_leaves_raw_data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Change working directory\n",
    "\n",
    "Change working directory from current to parent folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/workspace/mildew-detection\")\n",
    "print(\"You set a new current directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm new current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "! chmod 600 kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dataset path from the !(Kaggle url)[https://www.kaggle.com/datasets/codeinstitute/cherry-leaves] and set the destination folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KaggleDatasetPathway = \"codeinstitute/cherry-leaves\"\n",
    "DestinationFolder = \"inputs/cherry_leaves_raw_dataset\"\n",
    "! kaggle datasets download -d {KaggleDatasetPathway} -p {DestinationFolder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip the data from the zipfile, and then delete the zipfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(DestinationFolder + \"/\" + \"cherry-leaves.zip\", \"r\") as zip:\n",
    "    zip.extractall(DestinationFolder)\n",
    "os.remove(DestinationFolder + \"/\" + \"cherry-leaves.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove non-image files from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_image_file(my_data_dir):\n",
    "    image_extension = ('.png', '.jpg', '.jpeg')\n",
    "    folders = os.listdir(my_data_dir) \n",
    "    for folder in folders:\n",
    "        files = os.listdir(my_data_dir + '/' + folder)\n",
    "        \n",
    "            #print(files)\n",
    "        i = []\n",
    "        j = []\n",
    "        for given_file in files:\n",
    "            if not given_file.lower().endswith(image_extension):\n",
    "                file_location = my_data_dir + '/' + folder + '/' + given_file\n",
    "                os.remove(file_location) # remove non image file\n",
    "                i.append(1)\n",
    "            else:\n",
    "                j.append(1)\n",
    "                pass\n",
    "        print(f\"Folder: {folder} - has image file\",len(j))\n",
    "        print(f\"Folder: {folder} - has non-image file\",len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_non_image_file(my_data_dir='inputs/cherry_leaves_raw_dataset/cherry-leaves/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
    "\n",
    "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
    "        print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum to 1.0\")\n",
    "        return\n",
    "\n",
    "    # Gets class labels\n",
    "    labels = os.listdir(my_data_dir)  # retrieve folder names\n",
    "\n",
    "    if 'test' in labels:\n",
    "        pass\n",
    "    else:\n",
    "        # Create train, validation, and test folders with class label sub-folders\n",
    "        for folder in ['train', 'validation', 'test']:\n",
    "            for label in labels:\n",
    "                os.makedirs(name=os.path.join(my_data_dir, folder, label))\n",
    "\n",
    "        for label in labels:\n",
    "            files = os.listdir(os.path.join(my_data_dir, label))\n",
    "            random.shuffle(files)\n",
    "\n",
    "            train_set_files_qty = int(len(files) * train_set_ratio)\n",
    "            validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
    "\n",
    "            count = 1\n",
    "            # Move files to train set until full, then validation set until full, then test set\n",
    "            for file_name in files:\n",
    "                if count <= train_set_files_qty:\n",
    "                    # Move a file to the train set\n",
    "                    shutil.move(os.path.join(my_data_dir, label, file_name),\n",
    "                                os.path.join(my_data_dir, 'train', label, file_name))\n",
    "\n",
    "                elif count <= (train_set_files_qty + validation_set_files_qty):\n",
    "                    # Move a file to the validation set\n",
    "                    shutil.move(os.path.join(my_data_dir, label, file_name),\n",
    "                                os.path.join(my_data_dir, 'validation', label, file_name))\n",
    "\n",
    "                else:\n",
    "                    # Move a file to the test set\n",
    "                    shutil.move(os.path.join(my_data_dir, label, file_name),\n",
    "                                os.path.join(my_data_dir, 'test', label, file_name))\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            os.rmdir(os.path.join(my_data_dir, label))\n",
    "        \n",
    "        # Print the number of files in each set after splitting\n",
    "        print(\"Number of files in Train set:\")\n",
    "        for label in labels:\n",
    "            train_files = os.listdir(my_data_dir + '/train/' + label)\n",
    "            print(f\"Class {label}: {len(train_files)}\")\n",
    "\n",
    "        print(\"\\nNumber of files in Validation set:\")\n",
    "        for label in labels:\n",
    "            validation_files = os.listdir(my_data_dir + '/validation/' + label)\n",
    "            print(f\"Class {label}: {len(validation_files)}\")\n",
    "\n",
    "        print(\"\\nNumber of files in Test set:\")\n",
    "        for label in labels:\n",
    "            test_files = os.listdir(my_data_dir + '/test/' + label)\n",
    "            print(f\"Class {label}: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard 70/10/20% split is used for train/validation/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_validation_test_images(my_data_dir=f\"/workspace/mildew-detection/inputs/cherry_leaves_raw_dataset/cherry-leaves\",\n",
    "                                   train_set_ratio=0.7,\n",
    "                                   validation_set_ratio=0.1,\n",
    "                                   test_set_ratio=0.2\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "The data has been uploaded, extracted, any non-image files removed, and split into train, validation and test sets to be used in the modelling process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
