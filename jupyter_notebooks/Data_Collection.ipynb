{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "## Objective\n",
    "\n",
    "- Fetch and upload cherry leaves image dataset from Kaggle.\n",
    "- Prepare data for analysis and modelling.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- Kaggle authentification token [JSON file].\n",
    "- !(Kaggle dataset)[https://www.kaggle.com/codeinstitute/cherry-leaves].\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- Dataset split: train, validation, test sections.\n",
    "- Datasets saved to train, validation, test folders (within inputs/datasets/cherry_leaves_raw_data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Change working directory\n",
    "\n",
    "Change working directory from current to parent folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/mildew-detection/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/workspace/mildew-detection\")\n",
    "print(\"You set a new current directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm new current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/mildew-detection'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /home/gitpod/.pyenv/versions/3.8.12/lib/python3.8/site-packages (1.6.6)\n",
      "Requirement already satisfied: six>=1.10 in /home/gitpod/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /home/gitpod/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in /home/gitpod/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /home/gitpod/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/gitpod/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from kaggle) (4.66.2)\n",
      "Requirement already satisfied: python-slugify in /home/gitpod/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /home/gitpod/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from kaggle) (2.2.1)\n",
      "Requirement already satisfied: bleach in /home/gitpod/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in /home/gitpod/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/gitpod/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gitpod/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from requests->kaggle) (3.6)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/gitpod/.pyenv/versions/3.8.12/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "! chmod 600 kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dataset path from the !(Kaggle url)[https://www.kaggle.com/datasets/codeinstitute/cherry-leaves] and set the destination folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading cherry-leaves.zip to inputs/cherry_leaves_raw_dataset\n",
      " 84%|███████████████████████████████▊      | 46.0M/55.0M [00:00<00:00, 61.4MB/s]\n",
      "100%|██████████████████████████████████████| 55.0M/55.0M [00:00<00:00, 68.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "KaggleDatasetPathway = \"codeinstitute/cherry-leaves\"\n",
    "DestinationFolder = \"inputs/cherry_leaves_raw_dataset\"\n",
    "! kaggle datasets download -d {KaggleDatasetPathway} -p {DestinationFolder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip the data from the zipfile, and then delete the zipfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(DestinationFolder + \"/\" + \"cherry-leaves.zip\", \"r\") as zip:\n",
    "    zip.extractall(DestinationFolder)\n",
    "os.remove(DestinationFolder + \"/\" + \"cherry-leaves.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\t\t   kaggle.json\tREADME.md\t  runtime.txt\n",
      "jupyter_notebooks  Procfile\trequirements.txt  setup.sh\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove non-image files from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_image_file(my_data_dir):\n",
    "    image_extension = ('.png', '.jpg', '.jpeg')\n",
    "    folders = os.listdir(my_data_dir) \n",
    "    for folder in folders:\n",
    "        files = os.listdir(my_data_dir + '/' + folder)\n",
    "        \n",
    "            #print(files)\n",
    "        i = []\n",
    "        j = []\n",
    "        for given_file in files:\n",
    "            if not given_file.lower().endswith(image_extension):\n",
    "                file_location = my_data_dir + '/' + folder + '/' + given_file\n",
    "                os.remove(file_location) # remove non image file\n",
    "                i.append(1)\n",
    "            else:\n",
    "                j.append(1)\n",
    "                pass\n",
    "        print(f\"Folder: {folder} - has image file\",len(j))\n",
    "        print(f\"Folder: {folder} - has non-image file\",len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: healthy - has image file 2104\n",
      "Folder: healthy - has non-image file 0\n",
      "Folder: powdery_mildew - has image file 2104\n",
      "Folder: powdery_mildew - has non-image file 0\n"
     ]
    }
   ],
   "source": [
    "remove_non_image_file(my_data_dir='inputs/cherry_leaves_raw_dataset/cherry-leaves/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/workspace/mildew-detection/jupyter_notebooks/Data_Collection.ipynb Cell 20\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://caketaster-mildewdetect-r94d8fx043z.ws-us108.gitpod.io/workspace/mildew-detection/jupyter_notebooks/Data_Collection.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mshutil\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://caketaster-mildewdetect-r94d8fx043z.ws-us108.gitpod.io/workspace/mildew-detection/jupyter_notebooks/Data_Collection.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://caketaster-mildewdetect-r94d8fx043z.ws-us108.gitpod.io/workspace/mildew-detection/jupyter_notebooks/Data_Collection.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjoblib\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://caketaster-mildewdetect-r94d8fx043z.ws-us108.gitpod.io/workspace/mildew-detection/jupyter_notebooks/Data_Collection.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit_train_validation_test_images\u001b[39m(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n\u001b[1;32m      <a href='vscode-notebook-cell://caketaster-mildewdetect-r94d8fx043z.ws-us108.gitpod.io/workspace/mildew-detection/jupyter_notebooks/Data_Collection.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mif\u001b[39;00m train_set_ratio \u001b[39m+\u001b[39m validation_set_ratio \u001b[39m+\u001b[39m test_set_ratio \u001b[39m!=\u001b[39m \u001b[39m1.0\u001b[39m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'joblib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
    "\n",
    "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
    "        print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum to 1.0\")\n",
    "        return\n",
    "\n",
    "    # Gets class labels\n",
    "    labels = os.listdir(my_data_dir)  # retrieve folder names\n",
    "\n",
    "    if 'test' in labels:\n",
    "        pass\n",
    "    else:\n",
    "        # Create train, validation, and test folders with class label sub-folders\n",
    "        for folder in ['train', 'validation', 'test']:\n",
    "            for label in labels:\n",
    "                os.makedirs(name=os.path.join(my_data_dir, folder, label))\n",
    "\n",
    "        for label in labels:\n",
    "            files = os.listdir(os.path.join(my_data_dir, label))\n",
    "            random.shuffle(files)\n",
    "\n",
    "            train_set_files_qty = int(len(files) * train_set_ratio)\n",
    "            validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
    "\n",
    "            count = 1\n",
    "            # Move files to train set until full, then validation set until full, then test set\n",
    "            for file_name in files:\n",
    "                if count <= train_set_files_qty:\n",
    "                    # Move a file to the train set\n",
    "                    shutil.move(os.path.join(my_data_dir, label, file_name),\n",
    "                                os.path.join(my_data_dir, 'train', label, file_name))\n",
    "\n",
    "                elif count <= (train_set_files_qty + validation_set_files_qty):\n",
    "                    # Move a file to the validation set\n",
    "                    shutil.move(os.path.join(my_data_dir, label, file_name),\n",
    "                                os.path.join(my_data_dir, 'validation', label, file_name))\n",
    "\n",
    "                else:\n",
    "                    # Move a file to the test set\n",
    "                    shutil.move(os.path.join(my_data_dir, label, file_name),\n",
    "                                os.path.join(my_data_dir, 'test', label, file_name))\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            os.rmdir(os.path.join(my_data_dir, label))\n",
    "        \n",
    "        # Print the number of files in each set after splitting\n",
    "        print(\"Number of files in Train set:\")\n",
    "        for label in labels:\n",
    "            train_files = os.listdir(my_data_dir + '/train/' + label)\n",
    "            print(f\"Class {label}: {len(train_files)}\")\n",
    "\n",
    "        print(\"\\nNumber of files in Validation set:\")\n",
    "        for label in labels:\n",
    "            validation_files = os.listdir(my_data_dir + '/validation/' + label)\n",
    "            print(f\"Class {label}: {len(validation_files)}\")\n",
    "\n",
    "        print(\"\\nNumber of files in Test set:\")\n",
    "        for label in labels:\n",
    "            test_files = os.listdir(my_data_dir + '/test/' + label)\n",
    "            print(f\"Class {label}: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard 70/10/20% split is used for train/validation/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_validation_test_images(my_data_dir=f\"inputs/cherry_leaves_raw_dataset/cherry-leaves\",\n",
    "                                   train_set_ratio=0.7,\n",
    "                                   validation_set_ratio=0.1,\n",
    "                                   test_set_ratio=0.2\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "The data has been uploaded, extracted and split into train, validation and test sets to be used in the modelling process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
